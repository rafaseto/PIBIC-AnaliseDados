{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa funções para o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processamento import *\n",
    "\n",
    "from dlisio import dlis\n",
    "import pandas as pd\n",
    "\n",
    "# A função 'glob' do módulo 'glob' é usada para procurar todos os arquivos em um diretório com determinada extensão\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_arquivos = []     # Armazena os nomes dos arquivos .dlis\n",
    "leituras_dlis = []      # Armazena as leituras dos arquivos .dlis\n",
    "nomes_anp = []          # Armazena os nomes obtidos das leituras\n",
    "\n",
    "for file in glob.glob(r'**/Data' + \"/*.dlis\", recursive=True):\n",
    "    # Salva o nome do arquivo\n",
    "    nomes_arquivos.append(file)\n",
    "\n",
    "    # Salva os dados da leitura\n",
    "    leitura, *tail = dlis.load(f'{file}')\n",
    "    leituras_dlis.append(leitura)\n",
    "\n",
    "    # Salva o nome do poço\n",
    "    nome = leitura.origins[0].well_name\n",
    "    nomes_anp.append(nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data\\\\1-brsa-551-se_brsa_raw.dlis', 'Data\\\\1-brsa-574-se_brsa_raw.dlis', 'Data\\\\1-brsa-595-se_brsa_raw-1.dlis', 'Data\\\\1-brsa-605-se_brsa_raw.dlis', 'Data\\\\1-brsa-659-se_brsa_raw.dlis', 'Data\\\\3-CP-1847-SE.dlis', 'Data\\\\3-CP-1848-SE.dlis', 'Data\\\\3-CP-1851-SE.dlis', 'Data\\\\3-CP-1853-SE.dlis', 'Data\\\\3-CP-1855-SE.dlis', 'Data\\\\3-CP-1857-SE.dlis']\n",
      "['1-FSG-1-SE', '1-FSJQ-1-SE', '1-BRSA-595-SE', '1-BRSA-605-SE', '1-BRSA-659-SE', '3-BRSA-900-SE', '3-BRSA-889-SE', '3-BRSA-912-SE', '3-BRSA-897-SE', '3-BRSA-910-SE', '3-BRSA-907-SE']\n"
     ]
    }
   ],
   "source": [
    "print(nomes_arquivos)\n",
    "print(nomes_anp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padroniza nomes fora do padão 'X-BRSA-XXX-SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_anp[0] = '1-BRSA-551-SE'\n",
    "nomes_anp[1] = '1-BRSA-574-SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-BRSA-551-SE',\n",
       " '1-BRSA-574-SE',\n",
       " '1-BRSA-595-SE',\n",
       " '1-BRSA-605-SE',\n",
       " '1-BRSA-659-SE',\n",
       " '3-BRSA-900-SE',\n",
       " '3-BRSA-889-SE',\n",
       " '3-BRSA-912-SE',\n",
       " '3-BRSA-897-SE',\n",
       " '3-BRSA-910-SE',\n",
       " '3-BRSA-907-SE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_anp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva os identificadores em 'nomes_anp_abreviados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_anp_abreviados = []   # Armazena os nomes abreviados (identificadores)\n",
    "\n",
    "for nome in nomes_anp:\n",
    "    nome_abreviado = nome[7:10]\n",
    "    nomes_anp_abreviados.append(nome_abreviado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['551', '574', '595', '605', '659', '900', '889', '912', '897', '910', '907']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_anp_abreviados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dicionário para armazenar os dados e respectivos nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'551': LogicalFile(AIT_SONIC_TLD_MCFL_018PUP),\n",
       " '574': LogicalFile(GEOLOAD.1),\n",
       " '595': LogicalFile(GEOLOAD.1),\n",
       " '605': LogicalFile(AIT_SONIC_TLD_MCFL_048PUC),\n",
       " '659': LogicalFile(GEOLOAD.1),\n",
       " '900': LogicalFile(GEOLOAD.1),\n",
       " '889': LogicalFile(GEOLOAD.1),\n",
       " '912': LogicalFile(GEOLOAD.1),\n",
       " '897': LogicalFile(GEOLOAD.1),\n",
       " '910': LogicalFile(GEOLOAD.1),\n",
       " '907': LogicalFile(GEOLOAD.1)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casa itens da lista 'nome_anp_abreviados' com os itens da lista 'leituras_dlis'\n",
    "pares = zip(nomes_anp_abreviados, leituras_dlis)\n",
    "\n",
    "# Cria dicionário 'dli_dict'\n",
    "dli_dict = dict(pares)\n",
    "dli_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa TODAS as curvas presentes nos .dlis de cada poço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {}\n",
    "\n",
    "for key, poco in dli_dict.items():\n",
    "    channels = poco.frames[0].channels\n",
    "    channels_list = [channel.name for channel in channels]\n",
    "    channels_dict[key] = channels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva as curvas presentes nos .dlis em arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Curvas_CSV/curvas_551.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_574.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_595.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_605.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_659.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_900.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_889.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_912.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_897.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_910.csv criado com sucesso\n",
      "Arquivo Curvas_CSV/curvas_907.csv criado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "for key, value in channels_dict.items():\n",
    "    file_name = f\"Curvas_CSV/curvas_{key}.csv\"\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Curva\", \"Poco\"])\n",
    "        for item in value:\n",
    "            writer.writerow([item, f'P_{key}'])\n",
    "\n",
    "    print(f\"Arquivo {file_name} criado com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatena os arquivos CSV das curvas em um único arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo curvas_pocos.csv criado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pasta = \"Curvas_CSV\"\n",
    "\n",
    "# Lista para armazenar os dataframes repectivos aos .csv\n",
    "df_list = []\n",
    "\n",
    "# Itera sobre a pasta Curvas_CSV\n",
    "for arquivo in os.listdir(pasta):\n",
    "    file_path = os.path.join(pasta, arquivo)\n",
    "\n",
    "    # Lê o arquivo CSV como um DF\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatena os DFs ao longo do eixo das colunas\n",
    "df_concat = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Salva o DF concatenado em um .csv\n",
    "df_concat.to_csv(\"curvas_pocos.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo curvas_pocos.csv criado com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dataframes para os poços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = dli_dict['574'].frames[0].curves()\n",
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlis_df_dict = {}   # Conterá os dataframes respectivos aos poços\n",
    "\n",
    "# Curvas de perfis escolhidas\n",
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'DRHO', 'HDRS', 'LLD', 'BSZ', 'BS', 'CALI', 'DCALI', 'PE', 'DTC']\n",
    "\n",
    "# Iterando sobre os arquivos lógicos de todos os poços (que estão armazenados em 'dli_dict'),\n",
    "# '.values()' se refere aos valores do dicionário (não às chaves)\n",
    "for chave, poco in dli_dict.items():\n",
    "\n",
    "    # Armazenando as curvas que serão utilizadas em uma lista\n",
    "    curvas_utilizadas = [\n",
    "        channel.name                                    # Os elementos da lista serão os nomes das curvas\n",
    "        for channel in poco.channels                    # As curvas são acessadas por meio de 'poco.channels'\n",
    "        if channel.name in curvas_escolhidas            # As curvas que não utilizaremos não serão armazenadas na lista\n",
    "    ]\n",
    "    conjunto_aux = set(curvas_utilizadas)\n",
    "    curvas_utilizadas_sem_duplicados = list(conjunto_aux)\n",
    "\n",
    "    curvas = poco.frames[0].curves()\n",
    "\n",
    "    # Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\n",
    "    dlis_df_dict[chave] = pd.DataFrame(curvas[curvas_utilizadas_sem_duplicados])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['551', '574', '595', '605', '659', '900', '889', '912', '897', '910', '907'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlis_df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma os valores -999.25 em nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    poco.replace([-999.25], [None], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando os mnemônicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplica_mnemonico(dlis_df_dict, ['BS', 'BSZ'], 'BS')\n",
    "aplica_mnemonico(dlis_df_dict, ['LLD', 'HDRS'], 'RESD')\n",
    "aplica_mnemonico(dlis_df_dict, ['RHOB', 'RHOZ'], 'RHOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renomeia CALI para CAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    renomeia_coluna(poco, 'CALI', 'CAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona coluna DCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_DCAL(dlis_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenche os poços com curvas faltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se um dos poços não tiver uma dessas curvas, adicionamos a coluna da curva e mantemos os valores como None\n",
    "curvas_obrigatorias = ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
    "\n",
    "# Percorre todos os poços\n",
    "for poco in dlis_df_dict.values():\n",
    "    # Percorre todas as curvas obrigatórias\n",
    "    for curva in curvas_obrigatorias:\n",
    "        # Se o poço não tiver a curva\n",
    "        if curva not in poco.columns:\n",
    "            # Adiciona a coluna e os valores dela = None\n",
    "            poco[curva] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temos as seguintes curvas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "574: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "595: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "605: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "659: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "900: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "889: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "912: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "897: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "910: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "907: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dlis_df_dict.items():\n",
    "    curvas = sorted(poco.keys())\n",
    "    print(f\"{key}: {curvas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove valores DRHO e DCAL indesejados (Só depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limita_curva(dlis_df_dict, \"DRHO\", -0.15, 0.15)\n",
    "#limita_curva(dlis_df_dict, \"DCAL\", -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverte a ordem das linhas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordena os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_desejada = ['TDEP', 'GR', 'RESD', 'BS', 'CAL', 'DCAL', 'NPHI', 'PE', 'DRHO', 'RHOB', 'DTC']\n",
    "\n",
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].reindex(columns=ordem_desejada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva os dados dos dataframes em arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pocos_CSV/poco_551.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_574.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_595.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_605.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_659.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_900.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_889.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_912.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_897.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_910.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_907.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dlis_df_dict.items():\n",
    "    file_name = f\"Pocos_CSV/poco_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
