{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa funções para o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processamento import *\n",
    "\n",
    "from dlisio import dlis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# A função 'glob' do módulo 'glob' é usada para procurar todos os arquivos em um diretório com determinada extensão\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_arquivos = []     # Armazena os nomes dos arquivos .dlis\n",
    "leituras_dlis = []      # Armazena as leituras dos arquivos .dlis\n",
    "nomes_anp = []          # Armazena os nomes obtidos das leituras\n",
    "\n",
    "for file in glob.glob(r'**/Data' + \"/*.dlis\", recursive=True):\n",
    "    # Salva o nome do arquivo\n",
    "    nomes_arquivos.append(file)\n",
    "\n",
    "    # Salva os dados da leitura\n",
    "    leitura, *tail = dlis.load(f'{file}')\n",
    "    leituras_dlis.append(leitura)\n",
    "\n",
    "    # Salva o nome do poço\n",
    "    nome = leitura.origins[0].well_name\n",
    "    nomes_anp.append(nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data\\\\1-brsa-551-se_brsa_raw.dlis', 'Data\\\\1-brsa-574-se_brsa_raw.dlis', 'Data\\\\1-brsa-595-se_brsa_raw-1.dlis', 'Data\\\\1-brsa-605-se_brsa_raw.dlis', 'Data\\\\1-brsa-659-se_brsa_raw.dlis', 'Data\\\\3-CP-1847-SE.dlis', 'Data\\\\3-CP-1848-SE.dlis', 'Data\\\\3-CP-1851-SE.dlis', 'Data\\\\3-CP-1853-SE.dlis', 'Data\\\\3-CP-1855-SE.dlis', 'Data\\\\3-CP-1857-SE.dlis']\n",
      "['1-FSG-1-SE', '1-FSJQ-1-SE', '1-BRSA-595-SE', '1-BRSA-605-SE', '1-BRSA-659-SE', '3-BRSA-900-SE', '3-BRSA-889-SE', '3-BRSA-912-SE', '3-BRSA-897-SE', '3-BRSA-910-SE', '3-BRSA-907-SE']\n"
     ]
    }
   ],
   "source": [
    "print(nomes_arquivos)\n",
    "print(nomes_anp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padroniza nomes fora do padão 'X-BRSA-XXX-SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_anp[0] = '1-BRSA-551-SE'\n",
    "nomes_anp[1] = '1-BRSA-574-SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-BRSA-551-SE',\n",
       " '1-BRSA-574-SE',\n",
       " '1-BRSA-595-SE',\n",
       " '1-BRSA-605-SE',\n",
       " '1-BRSA-659-SE',\n",
       " '3-BRSA-900-SE',\n",
       " '3-BRSA-889-SE',\n",
       " '3-BRSA-912-SE',\n",
       " '3-BRSA-897-SE',\n",
       " '3-BRSA-910-SE',\n",
       " '3-BRSA-907-SE']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_anp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dicionário para armazenar os dados e respectivos nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-BRSA-551-SE': LogicalFile(AIT_SONIC_TLD_MCFL_018PUP),\n",
       " '1-BRSA-574-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-595-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-605-SE': LogicalFile(AIT_SONIC_TLD_MCFL_048PUC),\n",
       " '1-BRSA-659-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-900-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-889-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-912-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-897-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-910-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-907-SE': LogicalFile(GEOLOAD.1)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casa itens da lista 'nome_anp_abreviados' com os itens da lista 'leituras_dlis'\n",
    "pares = zip(nomes_anp, leituras_dlis)\n",
    "\n",
    "# Cria dicionário 'dli_dict'\n",
    "dli_dict = dict(pares)\n",
    "dli_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa TODAS as curvas presentes nos .dlis de cada poço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {}\n",
    "\n",
    "for key, poco in dli_dict.items():\n",
    "    channels_list = []\n",
    "    for frame in poco.frames:\n",
    "        channels = frame.channels\n",
    "        channels_list.append([channel.name for channel in channels])\n",
    "    channels_dict[key] = sum(channels_list, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatena os arquivos CSV das curvas em um único arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo curvas_pocos.csv criado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pasta = \"Curvas_CSV\"\n",
    "\n",
    "# Lista para armazenar os dataframes repectivos aos .csv\n",
    "df_list = []\n",
    "\n",
    "# Itera sobre a pasta Curvas_CSV\n",
    "for arquivo in os.listdir(pasta):\n",
    "    file_path = os.path.join(pasta, arquivo)\n",
    "\n",
    "    # Lê o arquivo CSV como um DF\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatena os DFs ao longo do eixo das colunas\n",
    "df_concat = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Salva o DF concatenado em um .csv\n",
    "df_concat.to_csv(\"curvas_pocos.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo curvas_pocos.csv criado com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dataframes para os poços"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns poços possuem mais de um 'frame'.\n",
    "\n",
    "Irei criar um 'dataframe' para cada um desses 'frames'.\n",
    "\n",
    "Irei fazer um 'JOIN' usando a coluna 'TDEP'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o teste com um poço apenas\n",
    "poco = dli_dict['1-BRSA-605-SE']\n",
    "\n",
    "# Dicionário para armazenar os dataframes dos frames do poço 605\n",
    "dataframes_605 = {}\n",
    "\n",
    "# Iterando sobre os frames do poço\n",
    "for frame in poco.frames:\n",
    "    # indice do frame\n",
    "    indice = poco.frames.index(frame)\n",
    "    \n",
    "    # obtendo os nomes das curvas \n",
    "    channels = frame.channels\n",
    "    curvas_nomes = [channel.name for channel in channels]\n",
    " \n",
    "    # obtendo os valores das curvas\n",
    "    curvas_valores = frame.curves()\n",
    "\n",
    "    dataframes_605[indice] = pd.DataFrame(curvas_valores, columns=curvas_nomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TDEP</th>\n",
       "      <th>BS</th>\n",
       "      <th>TENS</th>\n",
       "      <th>SP</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>TIME</th>\n",
       "      <th>IHV</th>\n",
       "      <th>ICV</th>\n",
       "      <th>DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264240.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>135.3750</td>\n",
       "      <td>47.261490</td>\n",
       "      <td>0.263958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.793983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264180.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>136.3125</td>\n",
       "      <td>47.261490</td>\n",
       "      <td>0.263958</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.793983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264120.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>135.7500</td>\n",
       "      <td>47.261490</td>\n",
       "      <td>0.263958</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.793983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264060.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>136.2500</td>\n",
       "      <td>47.261490</td>\n",
       "      <td>0.263958</td>\n",
       "      <td>1297.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.793983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>135.3750</td>\n",
       "      <td>47.261490</td>\n",
       "      <td>0.263958</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.793983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>10140.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>204.3750</td>\n",
       "      <td>59.688400</td>\n",
       "      <td>0.463366</td>\n",
       "      <td>808.5</td>\n",
       "      <td>16.101053</td>\n",
       "      <td>5.987124</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>10080.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>204.5625</td>\n",
       "      <td>59.507236</td>\n",
       "      <td>0.459518</td>\n",
       "      <td>825.5</td>\n",
       "      <td>16.101053</td>\n",
       "      <td>5.987124</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>10020.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>204.1875</td>\n",
       "      <td>59.372772</td>\n",
       "      <td>0.460849</td>\n",
       "      <td>810.5</td>\n",
       "      <td>16.101053</td>\n",
       "      <td>5.987124</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>9960.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>204.8750</td>\n",
       "      <td>60.822781</td>\n",
       "      <td>0.484079</td>\n",
       "      <td>824.5</td>\n",
       "      <td>16.101053</td>\n",
       "      <td>5.987124</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>9900.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>204.8750</td>\n",
       "      <td>60.822781</td>\n",
       "      <td>0.484079</td>\n",
       "      <td>808.5</td>\n",
       "      <td>16.101053</td>\n",
       "      <td>5.987124</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TDEP   BS    TENS        SP         GR      NPHI    TIME        IHV  \\\n",
       "0     264240.0  8.5  2009.0  135.3750  47.261490  0.263958     0.0   0.000000   \n",
       "1     264180.0  8.5  1731.0  136.3125  47.261490  0.263958  2184.0   0.000000   \n",
       "2     264120.0  8.5  1811.0  135.7500  47.261490  0.263958  1879.0   0.000000   \n",
       "3     264060.0  8.5  1776.0  136.2500  47.261490  0.263958  1297.5   0.000000   \n",
       "4     264000.0  8.5  1871.0  135.3750  47.261490  0.263958  1131.0   0.000000   \n",
       "...        ...  ...     ...       ...        ...       ...     ...        ...   \n",
       "4235   10140.0  8.5  1128.0  204.3750  59.688400  0.463366   808.5  16.101053   \n",
       "4236   10080.0  8.5  1136.0  204.5625  59.507236  0.459518   825.5  16.101053   \n",
       "4237   10020.0  8.5  1149.0  204.1875  59.372772  0.460849   810.5  16.101053   \n",
       "4238    9960.0  8.5  1162.0  204.8750  60.822781  0.484079   824.5  16.101053   \n",
       "4239    9900.0  8.5  1181.0  204.8750  60.822781  0.484079   808.5  16.101053   \n",
       "\n",
       "           ICV         DT  \n",
       "0     0.000000  82.793983  \n",
       "1     0.000000  82.793983  \n",
       "2     0.000000  82.793983  \n",
       "3     0.000000  82.793983  \n",
       "4     0.000000  82.793983  \n",
       "...        ...        ...  \n",
       "4235  5.987124  60.000000  \n",
       "4236  5.987124  60.000000  \n",
       "4237  5.987124  60.000000  \n",
       "4238  5.987124  60.000000  \n",
       "4239  5.987124  60.000000  \n",
       "\n",
       "[4240 rows x 10 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_605[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m poco \u001b[38;5;241m=\u001b[39m dli_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1-BRSA-605-SE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurves\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\n\u001b[0;32m      3\u001b[0m data\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'channels'"
     ]
    }
   ],
   "source": [
    "poco = dli_dict['1-BRSA-605-SE']\n",
    "data = poco.frames[2].curves().channels\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m poco\u001b[38;5;241m.\u001b[39mframes:\n\u001b[0;32m     25\u001b[0m     curvas \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mcurves()\n\u001b[1;32m---> 27\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dataframe, pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mcurvas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurvas_utilizadas_sem_duplicados\u001b[49m\u001b[43m]\u001b[49m)])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\u001b[39;00m\n\u001b[0;32m     30\u001b[0m dlis_df_dict[chave] \u001b[38;5;241m=\u001b[39m dataframe\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GR'"
     ]
    }
   ],
   "source": [
    "dlis_df_dict = {}   # Conterá os dataframes respectivos aos poços\n",
    "\n",
    "# Curvas de perfis escolhidas\n",
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'DRHO', 'HDRS', 'LLD', 'BSZ', 'BS', 'CALI', 'DCALI', 'DCAL', 'PE', 'DTC']\n",
    "\n",
    "# Iterando sobre os arquivos lógicos de todos os poços (que estão armazenados em 'dli_dict'),\n",
    "# '.values()' se refere aos valores do dicionário (não às chaves)\n",
    "for chave, poco in dli_dict.items():\n",
    "\n",
    "    # Armazenando as curvas que serão utilizadas em uma lista\n",
    "    curvas_utilizadas = [\n",
    "        channel.name                                    # Os elementos da lista serão os nomes das curvas\n",
    "        for channel in poco.channels                    # As curvas são acessadas por meio de 'poco.channels'\n",
    "        if channel.name in curvas_escolhidas            # As curvas que não utilizaremos não serão armazenadas na lista\n",
    "    ]\n",
    "    conjunto_aux = set(curvas_utilizadas)\n",
    "    curvas_utilizadas_sem_duplicados = list(conjunto_aux)\n",
    "    \n",
    "    #frames = [np.atleast_1d(frame) for frame in poco.frames]\n",
    "    #curvas = np.concatenate(frames, axis=0)\n",
    "    dataframe = pd.DataFrame()\n",
    "    \n",
    "    for frame in poco.frames:\n",
    "\n",
    "        curvas = frame.curves()\n",
    "\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame(curvas[curvas_utilizadas_sem_duplicados])])\n",
    "\n",
    "    # Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\n",
    "    dlis_df_dict[chave] = dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['551', '574', '595', '605', '659', '900', '889', '912', '897', '910', '907'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlis_df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma os valores -999.25 em nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    poco.replace([-999.25], [None], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando os mnemônicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplica_mnemonico(dlis_df_dict, ['BS', 'BSZ'], 'BS')\n",
    "aplica_mnemonico(dlis_df_dict, ['LLD', 'HDRS'], 'RESD')\n",
    "aplica_mnemonico(dlis_df_dict, ['RHOB', 'RHOZ'], 'RHOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renomeia CALI para CAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    renomeia_coluna(poco, 'CALI', 'CAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona coluna DCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_DCAL(dlis_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenche os poços com curvas faltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se um dos poços não tiver uma dessas curvas, adicionamos a coluna da curva e mantemos os valores como None\n",
    "curvas_obrigatorias = ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
    "\n",
    "# Percorre todos os poços\n",
    "for poco in dlis_df_dict.values():\n",
    "    # Percorre todas as curvas obrigatórias\n",
    "    for curva in curvas_obrigatorias:\n",
    "        # Se o poço não tiver a curva\n",
    "        if curva not in poco.columns:\n",
    "            # Adiciona a coluna e os valores dela = None\n",
    "            poco[curva] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temos as seguintes curvas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "574: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "595: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "605: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "659: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "900: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "889: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "912: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "897: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "910: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "907: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dlis_df_dict.items():\n",
    "    curvas = sorted(poco.keys())\n",
    "    print(f\"{key}: {curvas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove valores DRHO e DCAL indesejados (Só depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limita_curva(dlis_df_dict, \"DRHO\", -0.15, 0.15)\n",
    "#limita_curva(dlis_df_dict, \"DCAL\", -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverte a ordem das linhas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordena os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_desejada = ['TDEP', 'GR', 'RESD', 'BS', 'CAL', 'DCAL', 'NPHI', 'PE', 'DRHO', 'RHOB', 'DTC']\n",
    "\n",
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].reindex(columns=ordem_desejada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva os dados dos dataframes em arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pocos_CSV/poco_551.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_574.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_595.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_605.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_659.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_900.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_889.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_912.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_897.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_910.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_907.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dlis_df_dict.items():\n",
    "    file_name = f\"Pocos_CSV/poco_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
