{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa funções para o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processamento import *\n",
    "\n",
    "from dlisio import dlis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# A função 'glob' do módulo 'glob' é usada para procurar todos os arquivos em um diretório com determinada extensão\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_arquivos = []     # Armazena os nomes dos arquivos .dlis\n",
    "leituras_dlis = []      # Armazena as leituras dos arquivos .dlis\n",
    "nomes_anp = []          # Armazena os nomes obtidos das leituras\n",
    "\n",
    "for file in glob.glob(r'**/Dados-dlis' + \"/*.dlis\", recursive=True):\n",
    "    # Salva o nome do arquivo\n",
    "    nomes_arquivos.append(file)\n",
    "\n",
    "    # Salva os dados da leitura\n",
    "    leitura, *tail = dlis.load(f'{file}')\n",
    "    leituras_dlis.append(leitura)\n",
    "\n",
    "    # Salva o nome do poço\n",
    "    nome = leitura.origins[0].well_name\n",
    "    nomes_anp.append(nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dados-dlis\\\\1-brsa-551-se_brsa_raw.dlis', 'Dados-dlis\\\\1-brsa-574-se_brsa_raw.dlis', 'Dados-dlis\\\\1-brsa-595-se_brsa_raw-1.dlis', 'Dados-dlis\\\\1-brsa-605-se_brsa_raw.dlis', 'Dados-dlis\\\\1-brsa-659-se_brsa_raw.dlis']\n",
      "['1-FSG-1-SE', '1-FSJQ-1-SE', '1-BRSA-595-SE', '1-BRSA-605-SE', '1-BRSA-659-SE']\n"
     ]
    }
   ],
   "source": [
    "print(nomes_arquivos)\n",
    "print(nomes_anp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dicionário para armazenar os dados e respectivos nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-FSG-1-SE': LogicalFile(AIT_SONIC_TLD_MCFL_018PUP),\n",
       " '1-FSJQ-1-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-595-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-605-SE': LogicalFile(AIT_SONIC_TLD_MCFL_048PUC),\n",
       " '1-BRSA-659-SE': LogicalFile(GEOLOAD.1)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casa itens da lista 'nome_anp_abreviados' com os itens da lista 'leituras_dlis'\n",
    "pares = zip(nomes_anp, leituras_dlis)\n",
    "\n",
    "# Cria dicionário 'dli_dict'\n",
    "dli_dict = dict(pares)\n",
    "dli_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa TODAS as curvas presentes nos .dlis de cada poço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {}\n",
    "\n",
    "for key, poco in dli_dict.items():\n",
    "    channels_list = []\n",
    "    for frame in poco.frames:\n",
    "        channels = frame.channels\n",
    "        channels_list.append([channel.name for channel in channels])\n",
    "    channels_dict[key] = sum(channels_list, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatena os arquivos CSV das curvas em um único arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Curvas_CSV/curvas_pocos.csv criado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pasta = \"Curvas_CSV\"\n",
    "\n",
    "# Lista para armazenar os dataframes repectivos aos .csv\n",
    "df_list = []\n",
    "\n",
    "# Itera sobre a pasta Curvas_CSV\n",
    "for arquivo in os.listdir(pasta):\n",
    "    file_path = os.path.join(pasta, arquivo)\n",
    "\n",
    "    # Lê o arquivo CSV como um DF\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatena os DFs ao longo do eixo das colunas\n",
    "df_concat = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Salva o DF concatenado em um .csv\n",
    "df_concat.to_csv(\"Curvas_CSV/curvas_pocos.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo Curvas_CSV/curvas_pocos.csv criado com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processa os 'frames' dos poços 1-BRSA-551-SE e 1-BRSA-605-SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade de 'frames' dos poços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frame(60B), Frame(10B), Frame(5B), Frame(30B), Frame(120B), Frame(180B), Frame(20B), Frame(1B), Frame(2B)]\n",
      "[Frame(60B), Frame(10B), Frame(30B), Frame(20B)]\n"
     ]
    }
   ],
   "source": [
    "poco_551 = dli_dict['1-FSG-1-SE']\n",
    "poco_605 = dli_dict['1-BRSA-605-SE']\n",
    "\n",
    "print(poco_551.frames)\n",
    "print(poco_605.frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria um dicionário para armazenar os 'frames' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict_551 = {}\n",
    "frames_dict_605 = {}\n",
    "\n",
    "cria_frames_dict(frames_dict_551, poco_551)\n",
    "cria_frames_dict(frames_dict_605, poco_605)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria um 'dataframe' para cada 'frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'RHOZ', 'DRHO', 'BSZ', 'BS', 'HCAL', 'CAL', 'CALI', 'DCALI', 'DCAL', 'PE', 'DT', 'DTC', 'ILD', 'RILD', 'IEL', 'AIT90', 'AHT90', 'RT90', 'AT90', 'AO90', 'RT', 'AF90', 'AHF90', 'AFH90', 'LLD', 'RLLD', 'HDRS', 'HLLD', 'LL7', 'RLL7']\n",
    "\n",
    "dataframes_dict_551 = {}\n",
    "dataframes_dict_605 = {}\n",
    "\n",
    "cria_dataframes_dict(frames_dict_551, dataframes_dict_551, curvas_escolhidas)\n",
    "cria_dataframes_dict(frames_dict_605, dataframes_dict_605, curvas_escolhidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move a vírgula uma casa para a esquerda em todos os valores das colunas TDEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in dataframes_dict_551.values():\n",
    "    value[\"TDEP\"] = value[\"TDEP\"] / 10\n",
    "\n",
    "for value in dataframes_dict_605.values():\n",
    "    value[\"TDEP\"] = value[\"TDEP\"] / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converte de polegada para metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in dataframes_dict_551.values():\n",
    "    value[\"TDEP\"] = value[\"TDEP\"] * 0.0254\n",
    "\n",
    "for value in dataframes_dict_605.values():\n",
    "    value[\"TDEP\"] = value[\"TDEP\"] * 0.0254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salva os dataframes como arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Frames_551/frame_0.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_1.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_2.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_3.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_4.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_5.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_6.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_7.csv criado com sucesso.\n",
      "Arquivo Frames_551/frame_8.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_0.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_1.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_2.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_3.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataframes_dict_551.items():\n",
    "    file_name = f\"Frames_551/frame_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")\n",
    "\n",
    "for key, value in dataframes_dict_605.items():\n",
    "    file_name = f\"Frames_605/frame_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove valores de profundidade que não estão presentes no primeiro frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dataframes_dict_551.items():\n",
    "    dataframes_dict_551[key] = value[value[\"TDEP\"].isin(dataframes_dict_551[0][\"TDEP\"])]\n",
    "\n",
    "for key, value in dataframes_dict_605.items():\n",
    "    dataframes_dict_605[key] = value[value[\"TDEP\"].isin(dataframes_dict_605[0][\"TDEP\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Junta os 9 dataframes do poço 551 em um dataframe unificado\n",
    "\n",
    "#### Junta os 4 dataframes do poço 605 em um dataframe unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_unificado_551 = unifica_dataframes(dataframes_dict_551)\n",
    "dataframe_unificado_605 = unifica_dataframes(dataframes_dict_605)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mantém apenas uma curva de resistividade profunda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_unificado_filtrado_551 = remove_colunas(dataframe_unificado_551, ['RT', 'AHF90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dataframes para os demais poços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlis_df_dict = {}   # Conterá os dataframes respectivos aos poços\n",
    "\n",
    "# Curvas de perfis escolhidas\n",
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'RHOZ', 'DRHO', 'BSZ', 'BS', 'HCAL', 'CAL', 'CALI', 'DCALI', 'DCAL', 'PE', 'DT', 'DTC', 'ILD', 'RILD', 'IEL', 'AIT90', 'AHT90', 'RT90', 'AT90', 'AO90', 'RT', 'AF90', 'AHF90', 'AFH90', 'LLD', 'RLLD', 'HDRS', 'HLLD', 'LL7', 'RLL7']\n",
    "\n",
    "\n",
    "# Iterando sobre os arquivos lógicos de todos os poços (que estão armazenados em 'dli_dict'),\n",
    "# '.values()' se refere aos valores do dicionário (não às chaves)\n",
    "for chave, poco in dli_dict.items():\n",
    "\n",
    "    # Armazenando as curvas que serão utilizadas em uma lista\n",
    "    curvas_utilizadas = [\n",
    "        channel.name                                    # Os elementos da lista serão os nomes das curvas\n",
    "        for channel in poco.channels                    # As curvas são acessadas por meio de 'poco.channels'\n",
    "        if channel.name in curvas_escolhidas            # As curvas que não utilizaremos não serão armazenadas na lista\n",
    "    ]\n",
    "    conjunto_aux = set(curvas_utilizadas)\n",
    "    curvas_utilizadas_sem_duplicados = list(conjunto_aux)\n",
    "    \n",
    "    #frames = [np.atleast_1d(frame) for frame in poco.frames]\n",
    "    #curvas = np.concatenate(frames, axis=0)\n",
    "    try:\n",
    "        dataframe = pd.DataFrame()\n",
    "        \n",
    "        for frame in poco.frames:\n",
    "\n",
    "            curvas = frame.curves()\n",
    "\n",
    "            dataframe = pd.concat([dataframe, pd.DataFrame(curvas[curvas_utilizadas_sem_duplicados])])\n",
    "\n",
    "        # Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\n",
    "        dlis_df_dict[chave] = dataframe\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1-FSJQ-1-SE', '1-BRSA-595-SE', '1-BRSA-659-SE', '1-BRSA-605-SE', '1-FSG-1-SE'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlis_df_dict['1-BRSA-605-SE'] = dataframe_unificado_605\n",
    "dlis_df_dict['1-FSG-1-SE'] = dataframe_unificado_filtrado_551\n",
    "dlis_df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma os valores -999.25 em nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    poco.replace([-999.25], [None], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando os mnemônicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplica_mnemonico(dlis_df_dict, ['BS', 'BSZ'], 'BS')\n",
    "aplica_mnemonico(dlis_df_dict, ['LLD',\t'LL7',\t'RLLD',\t 'RLL7', 'HDRS', 'HLLD', 'ILD',\t'RILD',\t'IEL',\t'AIT90', 'AHT90', 'RT90', 'AT90', 'AO90', 'RT', 'AF90',\t'AHF90', 'AFH90'], 'RESD')\n",
    "aplica_mnemonico(dlis_df_dict, ['RHOB', 'RHOZ'], 'RHOB')\n",
    "aplica_mnemonico(dlis_df_dict, ['DTC', 'DT'], 'DT')\n",
    "aplica_mnemonico(dlis_df_dict, ['HCAL', 'CAL', 'CALI'], 'CAL')\n",
    "aplica_mnemonico(dlis_df_dict, ['DCAL', 'DCALI'], 'DCAL')\n",
    "aplica_mnemonico(dlis_df_dict, ['DRHO', 'HDRA'], 'DRHO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona coluna DCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_DCAL(dlis_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenche os poços com curvas faltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se um dos poços não tiver uma dessas curvas, adicionamos a coluna da curva e mantemos os valores como None\n",
    "curvas_obrigatorias = ['TDEP', 'BS', 'CAL', 'DCAL', 'GR', 'RESD', 'DT', 'RHOB', 'DRHO', 'NPHI', 'PE']\n",
    "\n",
    "# Percorre todos os poços\n",
    "for poco in dlis_df_dict.values():\n",
    "    # Percorre todas as curvas obrigatórias\n",
    "    for curva in curvas_obrigatorias:\n",
    "        # Se o poço não tiver a curva\n",
    "        if curva not in poco.columns:\n",
    "            # Adiciona a coluna e os valores dela = None\n",
    "            poco[curva] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temos as seguintes curvas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-FSJQ-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-595-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-659-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-605-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-FSG-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dlis_df_dict.items():\n",
    "    curvas = sorted(poco.keys())\n",
    "    print(f\"{key}: {curvas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove valores DRHO e DCAL indesejados (Só depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limita_curva(dlis_df_dict, \"DRHO\", -0.15, 0.15)\n",
    "#limita_curva(dlis_df_dict, \"DCAL\", -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverte a ordem das linhas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordena as colunas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simon e Vandelli vao definir a ordem de preferencia\n",
    "ordem_desejada = ['TDEP', 'BS', 'CAL', 'DCAL', 'GR', 'RESD', 'DT', 'RHOB', 'DRHO', 'NPHI', 'PE']\n",
    "\n",
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].reindex(columns=ordem_desejada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva os dados dos dataframes em arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pocos-pre-processados/poco_1-FSJQ-1-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-595-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-659-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-605-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-FSG-1-SE.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dlis_df_dict.items():\n",
    "    file_name = f\"Pocos-pre-processados/poco_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
