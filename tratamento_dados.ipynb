{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa funções para o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processamento import *\n",
    "\n",
    "from dlisio import dlis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# A função 'glob' do módulo 'glob' é usada para procurar todos os arquivos em um diretório com determinada extensão\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_arquivos = []     # Armazena os nomes dos arquivos .dlis\n",
    "leituras_dlis = []      # Armazena as leituras dos arquivos .dlis\n",
    "nomes_anp = []          # Armazena os nomes obtidos das leituras\n",
    "\n",
    "for file in glob.glob(r'**/Data' + \"/*.dlis\", recursive=True):\n",
    "    # Salva o nome do arquivo\n",
    "    nomes_arquivos.append(file)\n",
    "\n",
    "    # Salva os dados da leitura\n",
    "    leitura, *tail = dlis.load(f'{file}')\n",
    "    leituras_dlis.append(leitura)\n",
    "\n",
    "    # Salva o nome do poço\n",
    "    nome = leitura.origins[0].well_name\n",
    "    nomes_anp.append(nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data\\\\1-brsa-551-se_brsa_raw.dlis', 'Data\\\\1-brsa-574-se_brsa_raw.dlis', 'Data\\\\1-brsa-595-se_brsa_raw-1.dlis', 'Data\\\\1-brsa-605-se_brsa_raw.dlis', 'Data\\\\1-brsa-659-se_brsa_raw.dlis', 'Data\\\\3-CP-1847-SE.dlis', 'Data\\\\3-CP-1848-SE.dlis', 'Data\\\\3-CP-1851-SE.dlis', 'Data\\\\3-CP-1853-SE.dlis', 'Data\\\\3-CP-1855-SE.dlis', 'Data\\\\3-CP-1857-SE.dlis']\n",
      "['1-FSG-1-SE', '1-FSJQ-1-SE', '1-BRSA-595-SE', '1-BRSA-605-SE', '1-BRSA-659-SE', '3-BRSA-900-SE', '3-BRSA-889-SE', '3-BRSA-912-SE', '3-BRSA-897-SE', '3-BRSA-910-SE', '3-BRSA-907-SE']\n"
     ]
    }
   ],
   "source": [
    "print(nomes_arquivos)\n",
    "print(nomes_anp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padroniza nomes fora do padão 'X-BRSA-XXX-SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_anp[0] = '1-BRSA-551-SE'\n",
    "nomes_anp[1] = '1-BRSA-574-SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-BRSA-551-SE',\n",
       " '1-BRSA-574-SE',\n",
       " '1-BRSA-595-SE',\n",
       " '1-BRSA-605-SE',\n",
       " '1-BRSA-659-SE',\n",
       " '3-BRSA-900-SE',\n",
       " '3-BRSA-889-SE',\n",
       " '3-BRSA-912-SE',\n",
       " '3-BRSA-897-SE',\n",
       " '3-BRSA-910-SE',\n",
       " '3-BRSA-907-SE']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_anp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dicionário para armazenar os dados e respectivos nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-BRSA-551-SE': LogicalFile(AIT_SONIC_TLD_MCFL_018PUP),\n",
       " '1-BRSA-574-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-595-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-605-SE': LogicalFile(AIT_SONIC_TLD_MCFL_048PUC),\n",
       " '1-BRSA-659-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-900-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-889-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-912-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-897-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-910-SE': LogicalFile(GEOLOAD.1),\n",
       " '3-BRSA-907-SE': LogicalFile(GEOLOAD.1)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casa itens da lista 'nome_anp_abreviados' com os itens da lista 'leituras_dlis'\n",
    "pares = zip(nomes_anp, leituras_dlis)\n",
    "\n",
    "# Cria dicionário 'dli_dict'\n",
    "dli_dict = dict(pares)\n",
    "dli_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa TODAS as curvas presentes nos .dlis de cada poço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {}\n",
    "\n",
    "for key, poco in dli_dict.items():\n",
    "    channels_list = []\n",
    "    for frame in poco.frames:\n",
    "        channels = frame.channels\n",
    "        channels_list.append([channel.name for channel in channels])\n",
    "    channels_dict[key] = sum(channels_list, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatena os arquivos CSV das curvas em um único arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo curvas_pocos.csv criado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pasta = \"Curvas_CSV\"\n",
    "\n",
    "# Lista para armazenar os dataframes repectivos aos .csv\n",
    "df_list = []\n",
    "\n",
    "# Itera sobre a pasta Curvas_CSV\n",
    "for arquivo in os.listdir(pasta):\n",
    "    file_path = os.path.join(pasta, arquivo)\n",
    "\n",
    "    # Lê o arquivo CSV como um DF\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatena os DFs ao longo do eixo das colunas\n",
    "df_concat = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Salva o DF concatenado em um .csv\n",
    "df_concat.to_csv(\"curvas_pocos.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo curvas_pocos.csv criado com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisa os 'frames' dos poço 1-BRSA-605-SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade de 'frames' no poço 1-BRSA-605-SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Frame(60B), Frame(10B), Frame(30B), Frame(20B)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dli_dict['1-BRSA-605-SE'].frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria um 'dataframe' para cada 'frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_605 = {}\n",
    "poco = dli_dict['1-BRSA-605-SE']\n",
    "\n",
    "for frame in poco.frames:\n",
    "    indice = poco.frames.index(frame)\n",
    "\n",
    "    curves = pd.DataFrame(frame.curves())\n",
    "\n",
    "    dataframes_605[indice] = curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salva os dataframes como arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Frames_605/frame_0.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_1.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_2.csv criado com sucesso.\n",
      "Arquivo Frames_605/frame_3.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataframes_605.items():\n",
    "    file_name = f\"Frames_605/frame_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dli_dict['1-BRSA-605-SE'].frames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dataframes para os poços"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns poços possuem mais de um 'frame'.\n",
    "\n",
    "Irei criar um 'dataframe' para cada um desses 'frames'.\n",
    "\n",
    "Irei fazer um 'JOIN' usando a coluna 'TDEP'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria um dataframe para cada frame do poço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'RHOZ', 'DRHO', 'BSZ', 'BS', 'CALI', 'DCALI', 'DCAL', 'PE', 'DTC', 'ILD', 'RILD', 'IEL', 'AIT90', 'AHT90', 'RT90', 'AT90', 'AO90', 'RT', 'AF90', 'AHF90', 'AFH90', 'LLD', 'RLLD', 'HDRS', 'HLLD', 'LL7', 'RLL7']\n",
    "\n",
    "# Iniciando o teste com um poço apenas\n",
    "poco = dli_dict['1-BRSA-605-SE']\n",
    "\n",
    "# Dicionário para armazenar os dataframes dos frames do poço 605\n",
    "dataframes_605 = {}\n",
    "\n",
    "# Iterando sobre os frames do poço\n",
    "for frame in poco.frames:\n",
    "    # indice do frame\n",
    "    indice = poco.frames.index(frame)\n",
    "    \n",
    "    # obtendo os nomes das curvas \n",
    "    channels = frame.channels\n",
    "    curvas_nomes = [channel.name for channel in channels\n",
    "                    if channel.name in curvas_escolhidas]\n",
    " \n",
    "    # obtendo os valores das curvas\n",
    "    curvas_valores = frame.curves()\n",
    "\n",
    "    dataframes_605[indice] = pd.DataFrame(curvas_valores, columns=curvas_nomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = dataframes_605[0]\n",
    "\n",
    "for i in range(1, len(dataframes_605)):\n",
    "    df_merged = pd.merge(df_merged, dataframes_605[i], on='TDEP', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_merged.sort_values(by='TDEP')\n",
    "df_sorted.to_csv(\"teste_605.csv\", index=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m poco\u001b[38;5;241m.\u001b[39mframes:\n\u001b[0;32m     25\u001b[0m     curvas \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mcurves()\n\u001b[1;32m---> 27\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dataframe, pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mcurvas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurvas_utilizadas_sem_duplicados\u001b[49m\u001b[43m]\u001b[49m)])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\u001b[39;00m\n\u001b[0;32m     30\u001b[0m dlis_df_dict[chave] \u001b[38;5;241m=\u001b[39m dataframe\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GR'"
     ]
    }
   ],
   "source": [
    "dlis_df_dict = {}   # Conterá os dataframes respectivos aos poços\n",
    "\n",
    "# Curvas de perfis escolhidas\n",
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'DRHO', 'HDRS', 'LLD', 'BSZ', 'BS', 'CALI', 'DCALI', 'DCAL', 'PE', 'DTC']\n",
    "\n",
    "# Iterando sobre os arquivos lógicos de todos os poços (que estão armazenados em 'dli_dict'),\n",
    "# '.values()' se refere aos valores do dicionário (não às chaves)\n",
    "for chave, poco in dli_dict.items():\n",
    "\n",
    "    # Armazenando as curvas que serão utilizadas em uma lista\n",
    "    curvas_utilizadas = [\n",
    "        channel.name                                    # Os elementos da lista serão os nomes das curvas\n",
    "        for channel in poco.channels                    # As curvas são acessadas por meio de 'poco.channels'\n",
    "        if channel.name in curvas_escolhidas            # As curvas que não utilizaremos não serão armazenadas na lista\n",
    "    ]\n",
    "    conjunto_aux = set(curvas_utilizadas)\n",
    "    curvas_utilizadas_sem_duplicados = list(conjunto_aux)\n",
    "    \n",
    "    #frames = [np.atleast_1d(frame) for frame in poco.frames]\n",
    "    #curvas = np.concatenate(frames, axis=0)\n",
    "    dataframe = pd.DataFrame()\n",
    "    \n",
    "    for frame in poco.frames:\n",
    "\n",
    "        curvas = frame.curves()\n",
    "\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame(curvas[curvas_utilizadas_sem_duplicados])])\n",
    "\n",
    "    # Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\n",
    "    dlis_df_dict[chave] = dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['551', '574', '595', '605', '659', '900', '889', '912', '897', '910', '907'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlis_df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma os valores -999.25 em nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    poco.replace([-999.25], [None], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando os mnemônicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplica_mnemonico(dlis_df_dict, ['BS', 'BSZ'], 'BS')\n",
    "aplica_mnemonico(dlis_df_dict, ['LLD', 'HDRS'], 'RESD')\n",
    "aplica_mnemonico(dlis_df_dict, ['RHOB', 'RHOZ'], 'RHOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renomeia CALI para CAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dlis_df_dict.values():\n",
    "    renomeia_coluna(poco, 'CALI', 'CAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona coluna DCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_DCAL(dlis_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenche os poços com curvas faltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se um dos poços não tiver uma dessas curvas, adicionamos a coluna da curva e mantemos os valores como None\n",
    "curvas_obrigatorias = ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
    "\n",
    "# Percorre todos os poços\n",
    "for poco in dlis_df_dict.values():\n",
    "    # Percorre todas as curvas obrigatórias\n",
    "    for curva in curvas_obrigatorias:\n",
    "        # Se o poço não tiver a curva\n",
    "        if curva not in poco.columns:\n",
    "            # Adiciona a coluna e os valores dela = None\n",
    "            poco[curva] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temos as seguintes curvas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "574: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "595: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "605: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "659: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "900: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "889: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "912: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "897: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "910: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "907: ['BS', 'CAL', 'DCAL', 'DRHO', 'DTC', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dlis_df_dict.items():\n",
    "    curvas = sorted(poco.keys())\n",
    "    print(f\"{key}: {curvas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove valores DRHO e DCAL indesejados (Só depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limita_curva(dlis_df_dict, \"DRHO\", -0.15, 0.15)\n",
    "#limita_curva(dlis_df_dict, \"DCAL\", -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverte a ordem das linhas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordena as colunas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_desejada = ['TDEP', 'GR', 'RESD', 'BS', 'CAL', 'DCAL', 'NPHI', 'PE', 'DRHO', 'RHOB', 'DTC']\n",
    "\n",
    "for key in dlis_df_dict.keys():\n",
    "    dlis_df_dict[key] = dlis_df_dict[key].reindex(columns=ordem_desejada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva os dados dos dataframes em arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pocos_CSV/poco_551.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_574.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_595.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_605.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_659.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_900.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_889.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_912.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_897.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_910.csv criado com sucesso.\n",
      "Arquivo Pocos_CSV/poco_907.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dlis_df_dict.items():\n",
    "    file_name = f\"Pocos_CSV/poco_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
