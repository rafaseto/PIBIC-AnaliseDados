{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa funções para o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processamento import *\n",
    "\n",
    "from dlisio import dlis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# A função 'glob' do módulo 'glob' é usada para procurar todos os arquivos em um diretório com determinada extensão\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a realizar a busca por arquivos com extensão .dlis na pasta Dados-dlis, foi utilizada a função **glob()** da biblioteca glob.\n",
    "\n",
    "A leitura dos dados é feita com a função **load()** da biblioteca dlisio.\n",
    "\n",
    "São armazenados três tipos de dados:\n",
    "* **Nome do arquivo** na lista **nomes_arquivos**\n",
    "\n",
    "* **Dados das curvas** na lista **leituras_dlis**\n",
    "\n",
    "* **Nome do poço** na lista **nomes_anp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_arquivos = []     # Armazena os nomes dos arquivos .dlis\n",
    "leituras_dlis = []      # Armazena as leituras dos arquivos .dlis\n",
    "nomes_anp = []          # Armazena os nomes obtidos das leituras\n",
    "\n",
    "for file in glob.glob(r'**/Dados-dlis' + \"/*.dlis\", recursive=True):\n",
    "    try:\n",
    "        # Salva o nome do arquivo\n",
    "        nomes_arquivos.append(file)\n",
    "\n",
    "        # Salva os dados da leitura\n",
    "        leitura, *tail = dlis.load(f'{file}')\n",
    "        leituras_dlis.append(leitura)\n",
    "\n",
    "        # Salva o nome do poço\n",
    "        nome = leitura.origins[0].well_name\n",
    "        nomes_anp.append(nome)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dicionário para armazenar os dados e respectivos nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-FSG-1-SE': LogicalFile(AIT_SONIC_TLD_MCFL_018PUP),\n",
       " '1-FSJQ-1-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-595-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-BRSA-605-SE': LogicalFile(AIT_SONIC_TLD_MCFL_048PUC),\n",
       " '1-BRSA-659-SE': LogicalFile(GEOLOAD.1),\n",
       " '1-POI-1-SE': LogicalFile(AIT_SONIC_TLD_MCFL_024PUP),\n",
       " '1-BRSA-696-SE': LogicalFile(AIT_SONIC_TLD_MCFL_003PUP),\n",
       " '1-DP-2-SE': LogicalFile(AIT_SONIC_TLD_MCFL_079PUP)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casa itens da lista 'nome_anp_abreviados' com os itens da lista 'leituras_dlis'\n",
    "pares = zip(nomes_anp, leituras_dlis)\n",
    "\n",
    "# Cria dicionário 'dli_dict'\n",
    "dli_dict = dict(pares)\n",
    "dli_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa TODAS as curvas presentes nos .dlis de cada poço\n",
    "#### Para visualizar as curvas obtidas a partir da extração dos .dlis serão criados arquivos .csv com essas curvas presentes nos .dlis de cada poço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {}\n",
    "\n",
    "for key, poco in dli_dict.items():\n",
    "    channels_list = []\n",
    "    for frame in poco.frames:\n",
    "        channels = frame.channels\n",
    "        channels_list.append([channel.name for channel in channels])\n",
    "\n",
    "    channels_dict[key] = sum(channels_list, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos CSV criados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Para cada poço no dicionário channels_dict, criar um arquivo CSV\n",
    "for key, channels in channels_dict.items():\n",
    "    # Definir o nome do arquivo CSV usando o identificador do poço\n",
    "    filename = f'Curvas_CSV/{key}.csv'\n",
    "    \n",
    "    # Abrir o arquivo em modo de escrita\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Escrever o cabeçalho do CSV\n",
    "        writer.writerow(['Poco', 'Channel'])\n",
    "        \n",
    "        # Escrever uma linha para cada canal, incluindo o nome do poço\n",
    "        for channel in channels:\n",
    "            writer.writerow([key, channel])\n",
    "\n",
    "print(\"Arquivos CSV criados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatena os arquivos CSV das curvas em um único arquivo\n",
    "#### Para visualizar todas as curvas da extração dos .dlis em um único arquivo, os .csv de cada poço serão concatenados em um único arquivo .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\npasta = \"Curvas_CSV\"\\n\\n# Lista para armazenar os dataframes repectivos aos .csv\\ndf_list = []\\n\\n# Itera sobre a pasta Curvas_CSV\\nfor arquivo in os.listdir(pasta):\\n    file_path = os.path.join(pasta, arquivo)\\n\\n    # Lê o arquivo CSV como um DF\\n    df = pd.read_csv(file_path)\\n    df_list.append(df)\\n\\n# Concatena os DFs ao longo do eixo das colunas\\ndf_concat = pd.concat(df_list, axis=0, ignore_index=True)\\n\\n# Salva o DF concatenado em um .csv\\ndf_concat.to_csv(\"Curvas_CSV/curvas_pocos.csv\", index=False)\\n\\nprint(\"Arquivo Curvas_CSV/curvas_pocos.csv criado com sucesso\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "\n",
    "pasta = \"Curvas_CSV\"\n",
    "\n",
    "# Lista para armazenar os dataframes repectivos aos .csv\n",
    "df_list = []\n",
    "\n",
    "# Itera sobre a pasta Curvas_CSV\n",
    "for arquivo in os.listdir(pasta):\n",
    "    file_path = os.path.join(pasta, arquivo)\n",
    "\n",
    "    # Lê o arquivo CSV como um DF\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatena os DFs ao longo do eixo das colunas\n",
    "df_concat = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Salva o DF concatenado em um .csv\n",
    "df_concat.to_csv(\"Curvas_CSV/curvas_pocos.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo Curvas_CSV/curvas_pocos.csv criado com sucesso\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas escolhidas\n",
    "#### Cria uma lista para armazenar todas as curvas escolhidas e seus respectivos mnemônicos (alias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvas_escolhidas = ['TDEP', 'GR', 'NPHI', 'RHOB', 'RHOZ', 'DRHO', 'HDRA', 'BSZ', 'BS', 'HCAL', 'CAL', 'CALI', 'DCALI', 'DCAL', 'PE', 'PEFZ', 'PEU', 'DT', 'DTC', 'ILD', 'RILD', 'IEL', 'AIT90', 'AHT90', 'RT90', 'AT90', 'AO90', 'RT', 'AF90', 'AHF90', 'AFH90', 'LLD', 'RLLD', 'HDRS', 'HLLD', 'LL7', 'RLL7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processa os 'frames' dos poços 1-BRSA-551-SE e 1-BRSA-605-SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checa a quantidade de 'frames' dos poços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-FSG-1-SE: [Frame(60B), Frame(10B), Frame(5B), Frame(30B), Frame(120B), Frame(180B), Frame(20B), Frame(1B), Frame(2B)]\n",
      "1-FSJQ-1-SE: [Frame(50)]\n",
      "1-BRSA-595-SE: [Frame(50)]\n",
      "1-BRSA-605-SE: [Frame(60B), Frame(10B), Frame(30B), Frame(20B)]\n",
      "1-BRSA-659-SE: [Frame(50)]\n",
      "1-POI-1-SE: [Frame(60B), Frame(10B), Frame(5B), Frame(30B), Frame(120B), Frame(180B), Frame(20B), Frame(1B), Frame(2B)]\n",
      "1-BRSA-696-SE: [Frame(60B), Frame(10B), Frame(5B), Frame(30B), Frame(120B), Frame(180B), Frame(20B), Frame(1B), Frame(2B)]\n",
      "1-DP-2-SE: [Frame(60B), Frame(10B), Frame(5B), Frame(30B), Frame(120B), Frame(180B), Frame(20B), Frame(1B), Frame(2B)]\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dli_dict.items():\n",
    "    print(f'{key}: {poco.frames}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria um dicionário para armazenar os 'frames' dos poços com mais de um frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = {}\n",
    "\n",
    "for key, poco in dli_dict.items():\n",
    "    # if len(poco.frames) > 1:\n",
    "    frames_dict[key] = cria_frames_dict(poco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria um 'dataframe' para cada 'frame' dos poços com mais de um frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict = {}\n",
    "\n",
    "for key, poco_frames_dict in frames_dict.items():\n",
    "    dataframes_dict[key] = cria_dataframes_dict(poco_frames_dict, curvas_escolhidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salva os dataframes como arquivos (verificar onde colocar depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor key, value in dataframes_dict_551.items():\\n    file_name = f\"Frames_551/frame_{key}.csv\"\\n    value.to_csv(file_name, index=False)\\n    print(f\"Arquivo {file_name} criado com sucesso.\")\\n\\nfor key, value in dataframes_dict_605.items():\\n    file_name = f\"Frames_605/frame_{key}.csv\"\\n    value.to_csv(file_name, index=False)\\n    print(f\"Arquivo {file_name} criado com sucesso.\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for key, value in dataframes_dict_551.items():\n",
    "    file_name = f\"Frames_551/frame_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")\n",
    "\n",
    "for key, value in dataframes_dict_605.items():\n",
    "    file_name = f\"Frames_605/frame_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checa se todos os valores de profundidade presentes no primeiro frame existem nos demais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def checa_TDEP(dataframes, tolerancia=0.01):\n",
    "    tdep_primeiro_frame = dataframes[0]['TDEP']\n",
    "  \n",
    "    for key, value in dataframes.items():\n",
    "        if key == 0:  # Ignorar o primeiro DataFrame\n",
    "            continue\n",
    "        \n",
    "        tdep_outro_frame = dataframes[key]['TDEP']\n",
    "        \n",
    "        for valor_tdep in tdep_primeiro_frame:\n",
    "            # Verifica se algum valor em tdep_outro_frame está próximo o suficiente de valor_tdep\n",
    "            if any(math.isclose(valor_tdep, outro_valor, abs_tol=tolerancia) for outro_valor in tdep_outro_frame):\n",
    "                print(f'{valor_tdep} - Ok')\n",
    "            else:\n",
    "                print(f'{valor_tdep} - Faltando')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove valores de profundidade que não estão presentes no primeiro frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco_dataframes_dict in dataframes_dict.values():\n",
    "    for key, value in poco_dataframes_dict.items():\n",
    "        poco_dataframes_dict[key] = value[value['TDEP'].isin(poco_dataframes_dict[0]['TDEP'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Junta os dataframes dos poços em um único dataframe com as curvas escolhidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dataframes_dict.items():\n",
    "    dataframes_dict[key] = unifica_dataframes(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mantém apenas uma curva de resistividade profunda (RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dataframes_dict.items():\n",
    "    if 'RT' in value:\n",
    "        dataframes_dict[key] = remove_colunas(value, ['AHT90', 'AHF90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria dataframes para os demais poços (não é mais necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Iterando sobre os arquivos lógicos de todos os poços (que estão armazenados em 'dli_dict'),\\n# '.values()' se refere aos valores do dicionário (não às chaves)\\nfor chave, poco in dli_dict.items():\\n\\n    # Armazenando as curvas que serão utilizadas em uma lista\\n    curvas_utilizadas = [\\n        channel.name                                    # Os elementos da lista serão os nomes das curvas\\n        for channel in poco.channels                    # As curvas são acessadas por meio de 'poco.channels'\\n        if channel.name in curvas_escolhidas            # As curvas que não utilizaremos não serão armazenadas na lista\\n    ]\\n    conjunto_aux = set(curvas_utilizadas)\\n    curvas_utilizadas_sem_duplicados = list(conjunto_aux)\\n    \\n    #frames = [np.atleast_1d(frame) for frame in poco.frames]\\n    #curvas = np.concatenate(frames, axis=0)\\n    try:\\n        dataframe = pd.DataFrame()\\n        \\n        for frame in poco.frames:\\n\\n            curvas = frame.curves()\\n\\n            dataframe = pd.concat([dataframe, pd.DataFrame(curvas[curvas_utilizadas_sem_duplicados])])\\n\\n        # Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\\n        dataframes_dict[chave] = dataframe\\n    except:\\n        pass\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Iterando sobre os arquivos lógicos de todos os poços (que estão armazenados em 'dli_dict'),\n",
    "# '.values()' se refere aos valores do dicionário (não às chaves)\n",
    "for chave, poco in dli_dict.items():\n",
    "\n",
    "    # Armazenando as curvas que serão utilizadas em uma lista\n",
    "    curvas_utilizadas = [\n",
    "        channel.name                                    # Os elementos da lista serão os nomes das curvas\n",
    "        for channel in poco.channels                    # As curvas são acessadas por meio de 'poco.channels'\n",
    "        if channel.name in curvas_escolhidas            # As curvas que não utilizaremos não serão armazenadas na lista\n",
    "    ]\n",
    "    conjunto_aux = set(curvas_utilizadas)\n",
    "    curvas_utilizadas_sem_duplicados = list(conjunto_aux)\n",
    "    \n",
    "    #frames = [np.atleast_1d(frame) for frame in poco.frames]\n",
    "    #curvas = np.concatenate(frames, axis=0)\n",
    "    try:\n",
    "        dataframe = pd.DataFrame()\n",
    "        \n",
    "        for frame in poco.frames:\n",
    "\n",
    "            curvas = frame.curves()\n",
    "\n",
    "            dataframe = pd.concat([dataframe, pd.DataFrame(curvas[curvas_utilizadas_sem_duplicados])])\n",
    "\n",
    "        # Criando um pandas dataframe do poço respectivo à atual iteração e armazenando o mesmo em dlis_df\n",
    "        dataframes_dict[chave] = dataframe\n",
    "    except:\n",
    "        pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict['1-BRSA-659-SE'] = remove_colunas(dataframes_dict['1-BRSA-659-SE'], ['PEU'])\n",
    "dataframes_dict['1-FSJQ-1-SE'] = remove_colunas(dataframes_dict['1-FSJQ-1-SE'], ['PEU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checa a unidade de medida da coluna TDEP. Se for em polegada, move a vírgula uma casa para a esquerda em todos os valores das colunas TDEP e converte a unidade de medida de polegada para metro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key, value in dataframes_dict.items():\n",
    "    unidade_medida = dli_dict[key].frames[0].attic['SPACING'].units\n",
    "    \n",
    "    if unidade_medida == '0.1 in':\n",
    "        #for value in poco_dataframes_dict.values():\n",
    "        # move vírgula uma casa para a esquerda\n",
    "        value['TDEP'] = value['TDEP'] / 10\n",
    "\n",
    "        # converte de polegada para metro\n",
    "        value['TDEP'] = value['TDEP'] * 0.0254\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma os valores -999.25 em nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for poco in dataframes_dict.values():\n",
    "    poco.replace([-999.25], [None], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando os mnemônicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplica_mnemonico(dataframes_dict, ['BS', 'BSZ'], 'BS')\n",
    "aplica_mnemonico(dataframes_dict, ['LLD',\t'LL7',\t'RLLD',\t 'RLL7', 'HDRS', 'HLLD', 'ILD',\t'RILD',\t'IEL',\t'AIT90', 'AHT90', 'RT90', 'AT90', 'AO90', 'RT', 'AF90',\t'AHF90', 'AFH90'], 'RESD')\n",
    "aplica_mnemonico(dataframes_dict, ['RHOB', 'RHOZ'], 'RHOB')\n",
    "aplica_mnemonico(dataframes_dict, ['DTC', 'DT'], 'DT')\n",
    "aplica_mnemonico(dataframes_dict, ['HCAL', 'CAL', 'CALI'], 'CAL')\n",
    "aplica_mnemonico(dataframes_dict, ['DCAL', 'DCALI'], 'DCAL')\n",
    "aplica_mnemonico(dataframes_dict, ['DRHO', 'HDRA'], 'DRHO')\n",
    "aplica_mnemonico(dataframes_dict, ['PE', 'PEFZ', 'PEU'], 'PE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona coluna DCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_DCAL(dataframes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-FSG-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-FSJQ-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-595-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-605-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-659-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-POI-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-696-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-DP-2-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dataframes_dict.items():\n",
    "    curvas = sorted(poco.keys())\n",
    "    print(f\"{key}: {curvas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenche os poços com curvas faltando (não é mais necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Se um dos poços não tiver uma dessas curvas, adicionamos a coluna da curva e mantemos os valores como None\\ncurvas_obrigatorias = ['TDEP', 'BS', 'CAL', 'DCAL', 'GR', 'RESD', 'DT', 'RHOB', 'DRHO', 'NPHI', 'PE']\\n\\n# Percorre todos os poços\\nfor poco in dataframes_dict.values():\\n    # Percorre todas as curvas obrigatórias\\n    for curva in curvas_obrigatorias:\\n        # Se o poço não tiver a curva\\n        if curva not in poco.columns:\\n            # Adiciona a coluna e os valores dela = None\\n            poco[curva] = None\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Se um dos poços não tiver uma dessas curvas, adicionamos a coluna da curva e mantemos os valores como None\n",
    "curvas_obrigatorias = ['TDEP', 'BS', 'CAL', 'DCAL', 'GR', 'RESD', 'DT', 'RHOB', 'DRHO', 'NPHI', 'PE']\n",
    "\n",
    "# Percorre todos os poços\n",
    "for poco in dataframes_dict.values():\n",
    "    # Percorre todas as curvas obrigatórias\n",
    "    for curva in curvas_obrigatorias:\n",
    "        # Se o poço não tiver a curva\n",
    "        if curva not in poco.columns:\n",
    "            # Adiciona a coluna e os valores dela = None\n",
    "            poco[curva] = None\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temos as seguintes curvas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-FSG-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-FSJQ-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-595-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-605-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-659-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-POI-1-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-BRSA-696-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n",
      "1-DP-2-SE: ['BS', 'CAL', 'DCAL', 'DRHO', 'DT', 'GR', 'NPHI', 'PE', 'RESD', 'RHOB', 'TDEP']\n"
     ]
    }
   ],
   "source": [
    "for key, poco in dataframes_dict.items():\n",
    "    curvas = sorted(poco.keys())\n",
    "    print(f\"{key}: {curvas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove valores DRHO e DCAL indesejados (Só depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limita_curva(dataframes_dict, \"DRHO\", -0.15, 0.15)\n",
    "#limita_curva(dataframes_dict, \"DCAL\", -2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverte a ordem das linhas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dataframes_dict.keys():\n",
    "    dataframes_dict[key] = dataframes_dict[key].iloc[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordena as colunas dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simon e Vandelli já definiram (maio/24)\n",
    "ordem_desejada = ['TDEP', 'BS', 'CAL', 'DCAL', 'GR', 'RESD', 'DT', 'RHOB', 'DRHO', 'NPHI', 'PE']\n",
    "\n",
    "for key in dataframes_dict.keys():\n",
    "    try:\n",
    "        dataframes_dict[key] = dataframes_dict[key].reindex(columns=ordem_desejada)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva os dados dos dataframes em arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Pocos-pre-processados/poco_1-FSG-1-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-FSJQ-1-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-595-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-605-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-659-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-POI-1-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-BRSA-696-SE.csv criado com sucesso.\n",
      "Arquivo Pocos-pre-processados/poco_1-DP-2-SE.csv criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataframes_dict.items():\n",
    "    file_name = f\"Pocos-pre-processados/poco_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor key, value in dataframes_dict.items():\\n    file_name = f\"Pocos-pre-processados-sem-conversao/poco_{key}.csv\"\\n    value.to_csv(file_name, index=False)\\n    print(f\"Arquivo {file_name} criado com sucesso.\")\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for key, value in dataframes_dict.items():\n",
    "    file_name = f\"Pocos-pre-processados-sem-conversao/poco_{key}.csv\"\n",
    "    value.to_csv(file_name, index=False)\n",
    "    print(f\"Arquivo {file_name} criado com sucesso.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das anomalias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anidrita nos poços P_595 e P_605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arredonda TDEP do P_595\n",
    "dataframes_dict['1-BRSA-595-SE']['TDEP'] = dataframes_dict['1-BRSA-595-SE']['TDEP'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as curvas de interesse nos dados da extração dos .dlis\n",
    "tdep_gr = ['TDEP', 'GR']\n",
    "dlis_595 = dataframes_dict['1-BRSA-595-SE'][tdep_gr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusao_595 = pd.read_csv('arquivos-secundarios/merged_1-BRSA-595-SE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as curvas de interesse nos dados da fusão\n",
    "profundidade_litologia_gr = ['Poço', 'Profundidade', 'Litologia', 'GR']\n",
    "fusao_595 = fusao_595[profundidade_litologia_gr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poço</th>\n",
       "      <th>Profundidade</th>\n",
       "      <th>Litologia</th>\n",
       "      <th>GR_x</th>\n",
       "      <th>TDEP</th>\n",
       "      <th>GR_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>30.0</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>23.341702</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.341702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>30.1</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>23.106503</td>\n",
       "      <td>30.1</td>\n",
       "      <td>23.106503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>30.2</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>22.753702</td>\n",
       "      <td>30.2</td>\n",
       "      <td>22.753702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>30.3</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>21.888773</td>\n",
       "      <td>30.3</td>\n",
       "      <td>21.888773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>30.4</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>21.289391</td>\n",
       "      <td>30.4</td>\n",
       "      <td>21.289391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>702.1</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>702.1</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>702.2</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>702.2</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>702.3</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>702.3</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>702.4</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>702.4</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>702.5</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6726 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Poço  Profundidade Litologia        GR_x   TDEP        GR_y\n",
       "0     1-BRSA-595-SE          30.0  DOLOMITO   23.341702   30.0   23.341702\n",
       "1     1-BRSA-595-SE          30.1  DOLOMITO   23.106503   30.1   23.106503\n",
       "2     1-BRSA-595-SE          30.2  DOLOMITO   22.753702   30.2   22.753702\n",
       "3     1-BRSA-595-SE          30.3  DOLOMITO   21.888773   30.3   21.888773\n",
       "4     1-BRSA-595-SE          30.4  DOLOMITO   21.289391   30.4   21.289391\n",
       "...             ...           ...       ...         ...    ...         ...\n",
       "6721  1-BRSA-595-SE         702.1  FOLHELHO  124.306984  702.1  124.306984\n",
       "6722  1-BRSA-595-SE         702.2  FOLHELHO  124.306984  702.2  124.306984\n",
       "6723  1-BRSA-595-SE         702.3  FOLHELHO  124.306984  702.3  124.306984\n",
       "6724  1-BRSA-595-SE         702.4  FOLHELHO  124.306984  702.4  124.306984\n",
       "6725  1-BRSA-595-SE         702.5  FOLHELHO         NaN  702.5        None\n",
       "\n",
       "[6726 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusao_595 = pd.merge(fusao_595, dlis_595, left_on='Profundidade', right_on='TDEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "renomeia_coluna(fusao_595, 'GR_x', 'GR_fusão')\n",
    "renomeia_coluna(fusao_595, 'GR_y', 'GR_dlis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "renomeia_coluna(fusao_595, 'Profundidade', 'Profundidade (fusão)')\n",
    "renomeia_coluna(fusao_595, 'TDEP', 'TDEP (dlis)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusao_595 = fusao_595.reindex(columns=['Poço', 'Litologia', 'Profundidade (fusão)', 'TDEP (dlis)', 'GR_fusão', 'GR_dlis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poço</th>\n",
       "      <th>Litologia</th>\n",
       "      <th>Profundidade (fusão)</th>\n",
       "      <th>TDEP (dlis)</th>\n",
       "      <th>GR_fusão</th>\n",
       "      <th>GR_dlis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.341702</td>\n",
       "      <td>23.341702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>30.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>23.106503</td>\n",
       "      <td>23.106503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>30.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>22.753702</td>\n",
       "      <td>22.753702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>30.3</td>\n",
       "      <td>30.3</td>\n",
       "      <td>21.888773</td>\n",
       "      <td>21.888773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>DOLOMITO</td>\n",
       "      <td>30.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>21.289391</td>\n",
       "      <td>21.289391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>702.1</td>\n",
       "      <td>702.1</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>702.2</td>\n",
       "      <td>702.2</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>702.3</td>\n",
       "      <td>702.3</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>702.4</td>\n",
       "      <td>702.4</td>\n",
       "      <td>124.306984</td>\n",
       "      <td>124.306984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>1-BRSA-595-SE</td>\n",
       "      <td>FOLHELHO</td>\n",
       "      <td>702.5</td>\n",
       "      <td>702.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6726 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Poço Litologia  Profundidade (fusão)  TDEP (dlis)    GR_fusão  \\\n",
       "0     1-BRSA-595-SE  DOLOMITO                  30.0         30.0   23.341702   \n",
       "1     1-BRSA-595-SE  DOLOMITO                  30.1         30.1   23.106503   \n",
       "2     1-BRSA-595-SE  DOLOMITO                  30.2         30.2   22.753702   \n",
       "3     1-BRSA-595-SE  DOLOMITO                  30.3         30.3   21.888773   \n",
       "4     1-BRSA-595-SE  DOLOMITO                  30.4         30.4   21.289391   \n",
       "...             ...       ...                   ...          ...         ...   \n",
       "6721  1-BRSA-595-SE  FOLHELHO                 702.1        702.1  124.306984   \n",
       "6722  1-BRSA-595-SE  FOLHELHO                 702.2        702.2  124.306984   \n",
       "6723  1-BRSA-595-SE  FOLHELHO                 702.3        702.3  124.306984   \n",
       "6724  1-BRSA-595-SE  FOLHELHO                 702.4        702.4  124.306984   \n",
       "6725  1-BRSA-595-SE  FOLHELHO                 702.5        702.5         NaN   \n",
       "\n",
       "         GR_dlis  \n",
       "0      23.341702  \n",
       "1      23.106503  \n",
       "2      22.753702  \n",
       "3      21.888773  \n",
       "4      21.289391  \n",
       "...          ...  \n",
       "6721  124.306984  \n",
       "6722  124.306984  \n",
       "6723  124.306984  \n",
       "6724  124.306984  \n",
       "6725        None  \n",
       "\n",
       "[6726 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusao_595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_595 = fusao_595.to_csv('test_595', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
